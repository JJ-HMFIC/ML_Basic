{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTxMLw9zRD/RfntspTyIto",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJ-HMFIC/ML_Basic/blob/main/ML_Basic_Ch10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ch 10"
      ],
      "metadata": {
        "id": "DiB4HQ1UtrdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "training_epochs = 15\n",
        "nb_classes = 10"
      ],
      "metadata": {
        "id": "bYm18o13j8wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "tZ8JWDDbkSUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# normalizing data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-gaqGDCkTAP",
        "outputId": "5a320731-717e-4ff8-bb48-f9067fd8da40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change data shape\n",
        "print(x_train.shape)  # (60000, 28, 28)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U70gO2UpkU1H",
        "outputId": "8c24a0c3-0e27-45d5-e6fc-b69d4f1b1fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change result to one-hot encoding\n",
        "# in tf1, one_hot= True in read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "# took care of it, but here we need to manually convert them\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "8BvqrZXfkXTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
        "# array([0, 2, 1, 2, 0])\n",
        "# `to_categorical` converts this into a matrix with as many columns as there are classes. The number of rows\n",
        "#  stays the same. to_categorical(labels)\n",
        "# array([[ 1.,  0.,  0.],\n",
        "#        [ 0.,  0.,  1.],\n",
        "#        [ 0.,  1.,  0.],\n",
        "#        [ 0.,  0.,  1.],\n",
        "#        [ 1.,  0.,  0.]], dtype=float32)\n",
        "import numpy as np\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=10, input_dim=784, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fMIq9RDkd-6",
        "outputId": "854f43ee-2e70-4947-c2d4-93d196f01633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7850 (30.66 KB)\n",
            "Trainable params: 7850 (30.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)\n",
        "\n",
        "predictions = tf.model.predict(x_test)\n",
        "print('Prediction: \\n', predictions)\n",
        "x_train\n",
        "score = model.evaluate(x_train, y_train)\n",
        "print('Accuracy: ', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwPgdnrQkjvy",
        "outputId": "e848caae-29f1-43d6-cec4-94a987332658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2485 - acc: 0.9314\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2473 - acc: 0.9319\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2464 - acc: 0.9320\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2452 - acc: 0.9321\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2446 - acc: 0.9328\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2432 - acc: 0.9329\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2426 - acc: 0.9337\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2418 - acc: 0.9333\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2411 - acc: 0.9337\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2402 - acc: 0.9335\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2394 - acc: 0.9341\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2391 - acc: 0.9342\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2385 - acc: 0.9343\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2380 - acc: 0.9344\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2372 - acc: 0.9347\n",
            "Prediction: \n",
            " [[0.07195974 0.18844126 0.08727005 ... 0.08386867 0.15926565 0.07274044]\n",
            " [0.10609416 0.11922567 0.07216123 ... 0.08365835 0.08843016 0.1000989 ]\n",
            " [0.09847093 0.10051269 0.07005971 ... 0.12860607 0.13877878 0.07224231]\n",
            " ...\n",
            " [0.10170269 0.12129522 0.08425565 ... 0.11100697 0.10779082 0.0615032 ]\n",
            " [0.05556226 0.14993636 0.09680306 ... 0.1117453  0.156725   0.05286568]\n",
            " [0.16227719 0.07174831 0.0766759  ... 0.11286785 0.05539077 0.07084187]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.93633336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기화를 잘 해야 한다. Xavier\n",
        "\n",
        "model2 = tf.keras.Sequential()\n",
        "\n",
        "# initializer 추가 및 활성화 함수 Relu\n",
        "model2.add(tf.keras.layers.Dense(input_dim=784, units=256, kernel_initializer='glorot_normal', activation='relu'))\n",
        "\n",
        "model2.add(tf.keras.layers.Dense(units=256, kernel_initializer='glorot_normal', activation='relu'))\n",
        "\n",
        "model2.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
        "\n",
        "#model2.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "                 optimizer='Adam', metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1GAIl2kn3WC",
        "outputId": "c7ff6980-2a6a-4eb6-d857-1704edc6cbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 269322 (1.03 MB)\n",
            "Trainable params: 269322 (1.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)\n",
        "\n",
        "predictions = tf.model.predict(x_test)\n",
        "print('Prediction: \\n', predictions)\n",
        "x_train\n",
        "score = model2.evaluate(x_train, y_train)\n",
        "evaluation = model2.evaluate(x_test, y_test)\n",
        "print('loss: ', evaluation[0])\n",
        "print('accuracy', evaluation[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FhswrJkpUQ5",
        "outputId": "3f6e3c79-010e-4675-968b-fa9d3ec8ab49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0404 - acc: 0.9865\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.0309 - acc: 0.9904\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0247 - acc: 0.9920\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0187 - acc: 0.9938\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0172 - acc: 0.9946\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0169 - acc: 0.9942\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0135 - acc: 0.9951\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0123 - acc: 0.9958\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0083 - acc: 0.9969\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0129 - acc: 0.9958\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0116 - acc: 0.9961\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0088 - acc: 0.9971\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 3s 54us/sample - loss: 0.0076 - acc: 0.9975\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0126 - acc: 0.9960\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.0056 - acc: 0.9982\n",
            "Prediction: \n",
            " [[0.07195974 0.18844126 0.08727005 ... 0.08386867 0.15926565 0.07274044]\n",
            " [0.10609416 0.11922567 0.07216123 ... 0.08365835 0.08843016 0.1000989 ]\n",
            " [0.09847093 0.10051269 0.07005971 ... 0.12860607 0.13877878 0.07224231]\n",
            " ...\n",
            " [0.10170269 0.12129522 0.08425565 ... 0.11100697 0.10779082 0.0615032 ]\n",
            " [0.05556226 0.14993636 0.09680306 ... 0.1117453  0.156725   0.05286568]\n",
            " [0.16227719 0.07174831 0.0766759  ... 0.11286785 0.05539077 0.07084187]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  0.09171097289970694\n",
            "accuracy 0.9817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기화를 잘 해야 한다. Xavier\n",
        "\n",
        "model3 = tf.keras.Sequential()\n",
        "\n",
        "# initializer 추가 및 활성화 함수 Relu\n",
        "model3.add(tf.keras.layers.Dense(input_dim=784, units=256, kernel_initializer='glorot_normal', activation='relu'))\n",
        "\n",
        "# 3겹의 hidden layer , 512로 넓게 설정\n",
        "model3.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "model3.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "model3.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "\n",
        "model3.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model3.summary()\n",
        "\n",
        "history = model3.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5fjDOfJpo3h",
        "outputId": "d85fe18c-55e7-4549-d06f-21f400238214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 862986 (3.29 MB)\n",
            "Trainable params: 862986 (3.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 19s 313us/sample - loss: 0.2202 - acc: 0.9338\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 15s 251us/sample - loss: 0.0938 - acc: 0.9714\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 12s 200us/sample - loss: 0.0661 - acc: 0.9796\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0536 - acc: 0.9831\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 11s 191us/sample - loss: 0.0434 - acc: 0.9862\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 12s 200us/sample - loss: 0.0344 - acc: 0.9889\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 11s 175us/sample - loss: 0.0317 - acc: 0.9901\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 11s 186us/sample - loss: 0.0276 - acc: 0.9912\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 12s 199us/sample - loss: 0.0245 - acc: 0.9923\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 11s 191us/sample - loss: 0.0239 - acc: 0.9927\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 10s 175us/sample - loss: 0.0227 - acc: 0.9929\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 12s 199us/sample - loss: 0.0173 - acc: 0.9946\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 11s 182us/sample - loss: 0.0173 - acc: 0.9949\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 11s 176us/sample - loss: 0.0178 - acc: 0.9950\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 12s 200us/sample - loss: 0.0148 - acc: 0.9952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model3.evaluate(x_test, y_test)\n",
        "print('loss: ', evaluation[0])\n",
        "print('accuracy', evaluation[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-pjo6hQrkdQ",
        "outputId": "3b05af7c-bd66-4aba-e92f-90d6416420ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  0.09681379528429433\n",
            "accuracy 0.9788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "★ hidden layer도 추가하고 더 넗게 layer를 펼쳤는데도 정확도는 소폭 하락\n",
        "\n",
        "이는 네트워크가 깊어지면 학습 데이터를 기억하여 오히려 test data를 시행 시 overfitting 발생함"
      ],
      "metadata": {
        "id": "MYShFimtsXQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_rate = 0.3\n",
        "\n",
        "model4 = tf.keras.Sequential()\n",
        "\n",
        "model4.add(tf.keras.layers.Dense(input_dim=784, units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "model4.add(tf.keras.layers.Dropout(drop_rate)) # drop out으로 layer 하나 추가\n",
        "\n",
        "model4.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "model4.add(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "model4.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "model4.add(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "model4.add(tf.keras.layers.Dense(units=512, kernel_initializer='glorot_normal', activation='relu'))\n",
        "model4.add(tf.keras.layers.Dropout(drop_rate))\n",
        "\n",
        "model4.add(tf.keras.layers.Dense(units=nb_classes, kernel_initializer='glorot_normal', activation='softmax'))\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        "                 optimizer='adam', metrics=['accuracy'])\n",
        "model4.summary()\n",
        "\n",
        "history = model4.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiy2NhX9sRkX",
        "outputId": "fb3d9587-67d9-4372-e5aa-40290e7d6450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_31 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1195018 (4.56 MB)\n",
            "Trainable params: 1195018 (4.56 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 19s 322us/sample - loss: 0.3075 - acc: 0.9061\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 16s 275us/sample - loss: 0.1462 - acc: 0.9573\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 16s 274us/sample - loss: 0.1169 - acc: 0.9664\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 27s 447us/sample - loss: 0.0938 - acc: 0.9727\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 18s 297us/sample - loss: 0.0838 - acc: 0.9758\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 16s 272us/sample - loss: 0.0796 - acc: 0.9769\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 17s 279us/sample - loss: 0.0671 - acc: 0.9802\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.0620 - acc: 0.9813\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 16s 275us/sample - loss: 0.0589 - acc: 0.9826\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 19s 316us/sample - loss: 0.0543 - acc: 0.9842\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 17s 287us/sample - loss: 0.0507 - acc: 0.9851\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 16s 274us/sample - loss: 0.0511 - acc: 0.9851\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 17s 275us/sample - loss: 0.0490 - acc: 0.9854\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 17s 275us/sample - loss: 0.0443 - acc: 0.9868\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 16s 272us/sample - loss: 0.0434 - acc: 0.9876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model4.evaluate(x_test, y_test)\n",
        "print('loss: ', evaluation[0])\n",
        "print('accuracy', evaluation[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZUbwYDTthYN",
        "outputId": "2e6cfee7-b75e-4a54-d6a5-e3427e0ae093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  0.07918642074084363\n",
            "accuracy 0.9817\n"
          ]
        }
      ]
    }
  ]
}