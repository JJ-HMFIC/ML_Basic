{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1Z4r2NQ0ar7bbG2PUa1sC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJ-HMFIC/ML_Basic/blob/main/ML_Basic_Ch09_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ch 09"
      ],
      "metadata": {
        "id": "BvnZ_0bhiSlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "sqRz4hP3iTQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)"
      ],
      "metadata": {
        "id": "GepdIolxi4DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_rdYQz2jLYq",
        "outputId": "07cf8f40-4e22-4f68-ed54-6b5c71bac0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, 2])\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "W = tf.Variable(tf.random_normal([2, 1]), name=\"weight\")\n",
        "b = tf.Variable(tf.random_normal([1]), name=\"bias\")"
      ],
      "metadata": {
        "id": "Ewpw8yxmi9Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
        "\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
      ],
      "metadata": {
        "id": "-bePhZqUjKUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
      ],
      "metadata": {
        "id": "cRlQWdT6jdcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    # Initialize TensorFlow variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(10001):\n",
        "        _, cost_val, w_val = sess.run(\n",
        "                  [train, cost, W], feed_dict={X: x_data, Y: y_data}\n",
        "        )\n",
        "        if step % 100 == 0:\n",
        "            print(step, cost_val, w_val)\n",
        "\n",
        "    # Accuracy report\n",
        "    h, c, a = sess.run(\n",
        "              [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
        "    )\n",
        "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_ImQR_vjgYC",
        "outputId": "1375258a-1641-41ab-f170-0fd50a3ac061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.2769378 [[-0.30392036]\n",
            " [ 0.48313394]]\n",
            "100 0.72318435 [[0.3752678]\n",
            " [0.8417751]]\n",
            "200 0.7064425 [[0.30353022]\n",
            " [0.55367196]]\n",
            "300 0.69911724 [[0.22416288]\n",
            " [0.35795036]]\n",
            "400 0.69583607 [[0.16117322]\n",
            " [0.23267703]]\n",
            "500 0.694362 [[0.11395881]\n",
            " [0.15216416]]\n",
            "600 0.69369745 [[0.0796503 ]\n",
            " [0.10006162]]\n",
            "700 0.69339687 [[0.05521097]\n",
            " [0.06611533]]\n",
            "800 0.69326067 [[0.03803694]\n",
            " [0.0438623 ]]\n",
            "900 0.6931988 [[0.02608481]\n",
            " [0.02919682]]\n",
            "1000 0.69317067 [[0.01782572]\n",
            " [0.01948818]]\n",
            "1100 0.6931579 [[0.01214884]\n",
            " [0.01303693]]\n",
            "1200 0.69315207 [[0.00826256]\n",
            " [0.00873699]]\n",
            "1300 0.69314945 [[0.00561034]\n",
            " [0.00586378]]\n",
            "1400 0.69314814 [[0.00380461]\n",
            " [0.00394001]]\n",
            "1500 0.6931476 [[0.0025775 ]\n",
            " [0.00264984]]\n",
            "1600 0.6931474 [[0.00174481]\n",
            " [0.00178346]]\n",
            "1700 0.69314724 [[0.00118041]\n",
            " [0.00120106]]\n",
            "1800 0.69314724 [[0.00079819]\n",
            " [0.00080922]]\n",
            "1900 0.6931472 [[0.00053954]\n",
            " [0.00054542]]\n",
            "2000 0.6931472 [[0.00036459]\n",
            " [0.00036773]]\n",
            "2100 0.6931472 [[0.0002463 ]\n",
            " [0.00024798]]\n",
            "2200 0.6931472 [[0.00016636]\n",
            " [0.00016725]]\n",
            "2300 0.69314724 [[0.00011235]\n",
            " [0.00011283]]\n",
            "2400 0.6931472 [[7.586299e-05]\n",
            " [7.612609e-05]]\n",
            "2500 0.6931472 [[5.1225423e-05]\n",
            " [5.1360352e-05]]\n",
            "2600 0.6931472 [[3.4580829e-05]\n",
            " [3.4657645e-05]]\n",
            "2700 0.6931472 [[2.3340885e-05]\n",
            " [2.3384906e-05]]\n",
            "2800 0.6931472 [[1.5753212e-05]\n",
            " [1.5774880e-05]]\n",
            "2900 0.6931472 [[1.06316847e-05]\n",
            " [1.06429225e-05]]\n",
            "3000 0.6931472 [[7.1820668e-06]\n",
            " [7.1888344e-06]]\n",
            "3100 0.6931472 [[4.8455668e-06]\n",
            " [4.8508441e-06]]\n",
            "3200 0.6931472 [[3.2660396e-06]\n",
            " [3.2668463e-06]]\n",
            "3300 0.6931472 [[2.2259394e-06]\n",
            " [2.2267461e-06]]\n",
            "3400 0.6931472 [[1.5151535e-06]\n",
            " [1.5159602e-06]]\n",
            "3500 0.6931472 [[1.0055302e-06]\n",
            " [1.0063369e-06]]\n",
            "3600 0.6931471 [[6.6578315e-07]\n",
            " [6.6658987e-07]]\n",
            "3700 0.6931472 [[4.839905e-07]\n",
            " [4.847972e-07]]\n",
            "3800 0.6931472 [[3.3497844e-07]\n",
            " [3.3578519e-07]]\n",
            "3900 0.6931471 [[1.8894650e-07]\n",
            " [1.8975325e-07]]\n",
            "4000 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4100 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4200 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4300 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4400 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4500 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4600 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4700 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4800 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "4900 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5000 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5100 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5200 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5300 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5400 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5500 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5600 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5700 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5800 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "5900 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6000 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6100 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6200 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6300 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6400 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6500 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6600 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6700 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6800 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "6900 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7000 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7100 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7200 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7300 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7400 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7500 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7600 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7700 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7800 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "7900 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8000 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8100 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8200 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8300 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8400 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8500 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8600 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8700 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8800 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "8900 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9000 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9100 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9200 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9300 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9400 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9500 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9600 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9700 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9800 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "9900 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "10000 0.6931472 [[1.3232187e-07]\n",
            " [1.3312862e-07]]\n",
            "\n",
            "Hypothesis:  [[0.49999997]\n",
            " [0.49999997]\n",
            " [0.49999997]\n",
            " [0.5       ]] \n",
            "Correct:  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] \n",
            "Accuracy:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
        "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
        "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
        "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
        "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
        "# neural network으로 두 개 레이어 생성"
      ],
      "metadata": {
        "id": "gM-fJkPQjoP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cost/loss function\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis>0.5 else False\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
        "\n",
        "# Launch graph\n",
        "with tf.Session() as sess:\n",
        "    # Initialize TensorFlow variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(10001):\n",
        "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
        "        if step % 100 == 0:\n",
        "            print(step, cost_val)\n",
        "\n",
        "    # Accuracy report\n",
        "    h, p, a = sess.run(\n",
        "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
        "    )\n",
        "\n",
        "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaL_JkOjkAKH",
        "outputId": "2272a15d-5946-486d-845c-52d674cc06f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0561693\n",
            "100 0.7060299\n",
            "200 0.69910824\n",
            "300 0.69516265\n",
            "400 0.69235057\n",
            "500 0.6897011\n",
            "600 0.6865179\n",
            "700 0.68219113\n",
            "800 0.6762085\n",
            "900 0.6683012\n",
            "1000 0.65854526\n",
            "1100 0.64726436\n",
            "1200 0.6348386\n",
            "1300 0.6216164\n",
            "1400 0.6079323\n",
            "1500 0.59411913\n",
            "1600 0.5804719\n",
            "1700 0.5671885\n",
            "1800 0.5543318\n",
            "1900 0.541822\n",
            "2000 0.5294492\n",
            "2100 0.51688623\n",
            "2200 0.50369614\n",
            "2300 0.4893375\n",
            "2400 0.47318566\n",
            "2500 0.45459747\n",
            "2600 0.43304092\n",
            "2700 0.40827423\n",
            "2800 0.38051116\n",
            "2900 0.3504837\n",
            "3000 0.31934714\n",
            "3100 0.28843722\n",
            "3200 0.25897098\n",
            "3300 0.23182634\n",
            "3400 0.20747074\n",
            "3500 0.18601687\n",
            "3600 0.16733599\n",
            "3700 0.15116815\n",
            "3800 0.13720362\n",
            "3900 0.1251328\n",
            "4000 0.114670984\n",
            "4100 0.105569266\n",
            "4200 0.0976151\n",
            "4300 0.090630114\n",
            "4400 0.084466055\n",
            "4500 0.078999594\n",
            "4600 0.07412864\n",
            "4700 0.069768414\n",
            "4800 0.06584814\n",
            "4900 0.062308826\n",
            "5000 0.05910083\n",
            "5100 0.056182384\n",
            "5200 0.053517964\n",
            "5300 0.051077478\n",
            "5400 0.048835203\n",
            "5500 0.046768997\n",
            "5600 0.044859804\n",
            "5700 0.04309111\n",
            "5800 0.041448575\n",
            "5900 0.039919667\n",
            "6000 0.038493443\n",
            "6100 0.03716023\n",
            "6200 0.035911515\n",
            "6300 0.034739815\n",
            "6400 0.033638436\n",
            "6500 0.0326014\n",
            "6600 0.031623423\n",
            "6700 0.030699689\n",
            "6800 0.029825993\n",
            "6900 0.02899846\n",
            "7000 0.02821373\n",
            "7100 0.02746851\n",
            "7200 0.026760027\n",
            "7300 0.02608566\n",
            "7400 0.025443133\n",
            "7500 0.02483027\n",
            "7600 0.024245083\n",
            "7700 0.023685802\n",
            "7800 0.023150804\n",
            "7900 0.02263853\n",
            "8000 0.022147622\n",
            "8100 0.021676801\n",
            "8200 0.02122489\n",
            "8300 0.020790787\n",
            "8400 0.020373475\n",
            "8500 0.019972038\n",
            "8600 0.019585587\n",
            "8700 0.019213315\n",
            "8800 0.018854449\n",
            "8900 0.018508347\n",
            "9000 0.01817433\n",
            "9100 0.017851777\n",
            "9200 0.017540103\n",
            "9300 0.017238792\n",
            "9400 0.016947372\n",
            "9500 0.016665343\n",
            "9600 0.016392257\n",
            "9700 0.016127732\n",
            "9800 0.015871366\n",
            "9900 0.015622803\n",
            "10000 0.015381659\n",
            "\n",
            "Hypothesis:\n",
            "[[0.01233887]\n",
            " [0.9833483 ]\n",
            " [0.9833665 ]\n",
            " [0.01541617]] \n",
            "Predicted:\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1') # input = 2 , output = 10\n",
        "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
        "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([10, 1]), name='weight2')# input = 10 , output = 1\n",
        "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
        "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
        "# neural network으로 두 개 레이어 생성"
      ],
      "metadata": {
        "id": "jjwodA7GkpzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cost/loss function\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis>0.5 else False\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
        "\n",
        "# Launch graph\n",
        "with tf.Session() as sess:\n",
        "    # Initialize TensorFlow variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(10001):\n",
        "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
        "        if step % 100 == 0:\n",
        "            print(step, cost_val)\n",
        "\n",
        "    # Accuracy report\n",
        "    h, p, a = sess.run(\n",
        "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
        "    )\n",
        "\n",
        "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0GuF59_lEoS",
        "outputId": "59a5594a-550e-4960-8424-b9ba773027f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.70481324\n",
            "100 0.6998604\n",
            "200 0.69603205\n",
            "300 0.69278634\n",
            "400 0.6897681\n",
            "500 0.68671405\n",
            "600 0.6834088\n",
            "700 0.67965484\n",
            "800 0.67525256\n",
            "900 0.669983\n",
            "1000 0.66359556\n",
            "1100 0.65580475\n",
            "1200 0.64630306\n",
            "1300 0.6347904\n",
            "1400 0.62102\n",
            "1500 0.6048404\n",
            "1600 0.58621156\n",
            "1700 0.56518435\n",
            "1800 0.5418536\n",
            "1900 0.5163212\n",
            "2000 0.4886915\n",
            "2100 0.4591133\n",
            "2200 0.42784876\n",
            "2300 0.39533803\n",
            "2400 0.36222014\n",
            "2500 0.32928577\n",
            "2600 0.29736742\n",
            "2700 0.26720855\n",
            "2800 0.23935944\n",
            "2900 0.21413523\n",
            "3000 0.1916314\n",
            "3100 0.17177357\n",
            "3200 0.15437795\n",
            "3300 0.13920285\n",
            "3400 0.12598789\n",
            "3500 0.11447856\n",
            "3600 0.1044398\n",
            "3700 0.095662445\n",
            "3800 0.08796398\n",
            "3900 0.08118812\n",
            "4000 0.07520191\n",
            "4100 0.06989269\n",
            "4200 0.065165594\n",
            "4300 0.06094049\n",
            "4400 0.057149902\n",
            "4500 0.053736717\n",
            "4600 0.050652396\n",
            "4700 0.047855955\n",
            "4800 0.045312196\n",
            "4900 0.042991187\n",
            "5000 0.040867202\n",
            "5100 0.038917985\n",
            "5200 0.037124462\n",
            "5300 0.035469983\n",
            "5400 0.033940043\n",
            "5500 0.03252204\n",
            "5600 0.031204954\n",
            "5700 0.029979013\n",
            "5800 0.028835641\n",
            "5900 0.027767323\n",
            "6000 0.026767258\n",
            "6100 0.02582952\n",
            "6200 0.024948753\n",
            "6300 0.024120238\n",
            "6400 0.023339678\n",
            "6500 0.022603264\n",
            "6600 0.021907555\n",
            "6700 0.02124941\n",
            "6800 0.020626027\n",
            "6900 0.02003489\n",
            "7000 0.019473637\n",
            "7100 0.018940182\n",
            "7200 0.01843261\n",
            "7300 0.01794916\n",
            "7400 0.017488196\n",
            "7500 0.017048366\n",
            "7600 0.016628195\n",
            "7700 0.01622649\n",
            "7800 0.015842143\n",
            "7900 0.015474078\n",
            "8000 0.015121331\n",
            "8100 0.014782995\n",
            "8200 0.014458232\n",
            "8300 0.014146319\n",
            "8400 0.013846481\n",
            "8500 0.013558092\n",
            "8600 0.0132805165\n",
            "8700 0.0130132325\n",
            "8800 0.012755658\n",
            "8900 0.012507267\n",
            "9000 0.012267647\n",
            "9100 0.012036323\n",
            "9200 0.011812924\n",
            "9300 0.011597023\n",
            "9400 0.011388283\n",
            "9500 0.011186397\n",
            "9600 0.010990996\n",
            "9700 0.010801792\n",
            "9800 0.01061851\n",
            "9900 0.010440919\n",
            "10000 0.010268743\n",
            "\n",
            "Hypothesis:\n",
            "[[0.00514148]\n",
            " [0.9909454 ]\n",
            " [0.98837763]\n",
            " [0.01501334]] \n",
            "Predicted:\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
        "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
        "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\n",
        "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
        "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\n",
        "b3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
        "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
        "\n",
        "W4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')\n",
        "b4 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
        "hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n"
      ],
      "metadata": {
        "id": "Ksl0ZyD3lJGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cost/loss function\n",
        "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis>0.5 else False\n",
        "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
        "\n",
        "# Launch graph\n",
        "with tf.Session() as sess:\n",
        "    # Initialize TensorFlow variables\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(10001):\n",
        "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
        "        if step % 100 == 0:\n",
        "            print(step, cost_val)\n",
        "\n",
        "    # Accuracy report\n",
        "    h, p, a = sess.run(\n",
        "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
        "    )\n",
        "\n",
        "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Axufkq9lYTh",
        "outputId": "ddb496d1-205e-4647-d5f3-0b1a5affa633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.2509726\n",
            "100 0.6916966\n",
            "200 0.6914928\n",
            "300 0.6912759\n",
            "400 0.6910411\n",
            "500 0.6907841\n",
            "600 0.69049895\n",
            "700 0.6901792\n",
            "800 0.68981725\n",
            "900 0.6894033\n",
            "1000 0.6889252\n",
            "1100 0.68836826\n",
            "1200 0.68771297\n",
            "1300 0.6869338\n",
            "1400 0.68599707\n",
            "1500 0.68485725\n",
            "1600 0.6834518\n",
            "1700 0.6816934\n",
            "1800 0.6794576\n",
            "1900 0.67656374\n",
            "2000 0.6727444\n",
            "2100 0.6675956\n",
            "2200 0.6605028\n",
            "2300 0.65053064\n",
            "2400 0.6362687\n",
            "2500 0.6155439\n",
            "2600 0.58480585\n",
            "2700 0.5382225\n",
            "2800 0.46769398\n",
            "2900 0.3685205\n",
            "3000 0.25576574\n",
            "3100 0.16327389\n",
            "3200 0.10503842\n",
            "3300 0.071578816\n",
            "3400 0.05191561\n",
            "3500 0.039669216\n",
            "3600 0.031575453\n",
            "3700 0.025943497\n",
            "3800 0.021853592\n",
            "3900 0.018777361\n",
            "4000 0.016395457\n",
            "4100 0.01450604\n",
            "4200 0.012976555\n",
            "4300 0.011716861\n",
            "4400 0.010663849\n",
            "4500 0.0097722\n",
            "4600 0.009008708\n",
            "4700 0.008348459\n",
            "4800 0.0077725025\n",
            "4900 0.0072661117\n",
            "5000 0.006817793\n",
            "5100 0.006418392\n",
            "5200 0.0060605034\n",
            "5300 0.005738206\n",
            "5400 0.0054465504\n",
            "5500 0.005181465\n",
            "5600 0.0049396027\n",
            "5700 0.0047181034\n",
            "5800 0.0045145717\n",
            "5900 0.004326947\n",
            "6000 0.0041535133\n",
            "6100 0.0039927084\n",
            "6200 0.0038432833\n",
            "6300 0.0037040368\n",
            "6400 0.0035740524\n",
            "6500 0.0034524288\n",
            "6600 0.003338401\n",
            "6700 0.0032312933\n",
            "6800 0.0031305351\n",
            "6900 0.0030355419\n",
            "7000 0.0029458639\n",
            "7100 0.0028611105\n",
            "7200 0.0027808622\n",
            "7300 0.0027047743\n",
            "7400 0.002632547\n",
            "7500 0.0025638808\n",
            "7600 0.0024985657\n",
            "7700 0.0024363322\n",
            "7800 0.0023769853\n",
            "7900 0.0023203455\n",
            "8000 0.0022661884\n",
            "8100 0.0022144236\n",
            "8200 0.0021648568\n",
            "8300 0.0021173533\n",
            "8400 0.002071808\n",
            "8500 0.002028087\n",
            "8600 0.0019860996\n",
            "8700 0.0019457117\n",
            "8800 0.0019069079\n",
            "8900 0.0018695091\n",
            "9000 0.0018335299\n",
            "9100 0.0017988209\n",
            "9200 0.0017653522\n",
            "9300 0.0017330637\n",
            "9400 0.0017018811\n",
            "9500 0.0016717443\n",
            "9600 0.0016426382\n",
            "9700 0.0016144584\n",
            "9800 0.0015871897\n",
            "9900 0.0015608026\n",
            "10000 0.0015352517\n",
            "\n",
            "Hypothesis:\n",
            "[[0.0014091 ]\n",
            " [0.99864787]\n",
            " [0.99840695]\n",
            " [0.00178089]] \n",
            "Predicted:\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:\n",
            "1.0\n"
          ]
        }
      ]
    }
  ]
}