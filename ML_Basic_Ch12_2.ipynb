{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMR5UM44SgbE9MoQWr05ln4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJ-HMFIC/ML_Basic/blob/main/ML_Basic_Ch12_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12-2"
      ],
      "metadata": {
        "id": "NllYeZxqwsHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \" if you want you\"\n",
        "idx2char = list(set(sample))  # index -> char\n",
        "char2idx = {c: i for i, c in enumerate(idx2char)}  # char -> idex"
      ],
      "metadata": {
        "id": "bYSRO7n8wTYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameters\n",
        "dic_size = len(char2idx)  # RNN input size (one hot size)\n",
        "hidden_size = len(char2idx)  # RNN output size\n",
        "num_classes = len(char2idx)  # final output size (RNN or softmax, etc.)\n",
        "batch_size = 1  # one sample data, one batch\n",
        "sequence_length = len(sample) - 1  # number of lstm rollings (unit #)\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "fyUk42rkwtI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_idx = [char2idx[c] for c in sample]  # char to index\n",
        "x_data = [sample_idx[:-1]]  # X data sample (0 ~ n-1) hello: hell\n",
        "y_data = [sample_idx[1:]]   # Y label sample (1 ~ n) hello: ello"
      ],
      "metadata": {
        "id": "G7bDHe82w0r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot_eager = tf.one_hot(x_data, num_classes)  # one hot: 1 -> 0 1 0 0 0 0 0 0 0 0\n",
        "x_one_hot_numpy = tf.keras.utils.to_categorical(x_data, num_classes)  # it'll generate numpy array, either way works\n",
        "y_one_hot_eager = tf.one_hot(y_data, num_classes)"
      ],
      "metadata": {
        "id": "uKSsRMVHw3Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential();\n",
        "model1.add(tf.keras.layers.\n",
        "             LSTM(units=num_classes, input_shape=(sequence_length, x_one_hot_eager.shape[2]), return_sequences=True))\n",
        "model1.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))\n",
        "model1.summary()\n",
        "model1.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                 metrics=['accuracy'])\n",
        "model1.fit(x_one_hot_eager, y_one_hot_eager, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27bUolQMw-NT",
        "outputId": "df1713f5-d5d1-42b5-ca52-d1a7bfe84111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 15, 10)            840       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDi  (None, 15, 10)            110       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 950 (3.71 KB)\n",
            "Trainable params: 950 (3.71 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3080 - accuracy: 0.1333\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3060 - accuracy: 0.1333\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3040 - accuracy: 0.1333\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3020 - accuracy: 0.1333\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3000 - accuracy: 0.2000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2980 - accuracy: 0.2000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2961 - accuracy: 0.2000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2941 - accuracy: 0.2000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2922 - accuracy: 0.2000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2903 - accuracy: 0.2000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2884 - accuracy: 0.2000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2865 - accuracy: 0.2000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2846 - accuracy: 0.2000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2827 - accuracy: 0.2000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2808 - accuracy: 0.2000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2789 - accuracy: 0.2000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2771 - accuracy: 0.2000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2752 - accuracy: 0.2000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2734 - accuracy: 0.2000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2715 - accuracy: 0.2000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2697 - accuracy: 0.2000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2679 - accuracy: 0.2000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2660 - accuracy: 0.2000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2642 - accuracy: 0.2000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2624 - accuracy: 0.2000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2605 - accuracy: 0.2000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2587 - accuracy: 0.2000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2568 - accuracy: 0.2000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2550 - accuracy: 0.2000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2532 - accuracy: 0.2000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2513 - accuracy: 0.2667\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2495 - accuracy: 0.2667\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2476 - accuracy: 0.2667\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2457 - accuracy: 0.2667\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2438 - accuracy: 0.3333\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2419 - accuracy: 0.3333\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2400 - accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2381 - accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2362 - accuracy: 0.3333\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2343 - accuracy: 0.4000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2323 - accuracy: 0.4000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2303 - accuracy: 0.4000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2283 - accuracy: 0.4000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2263 - accuracy: 0.4000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2243 - accuracy: 0.2667\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2223 - accuracy: 0.2667\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2202 - accuracy: 0.2667\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2181 - accuracy: 0.2667\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2160 - accuracy: 0.2667\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2139 - accuracy: 0.2667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c5ceda5ae90>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model1.predict(x_one_hot_eager)\n",
        "\n",
        "for i, prediction in enumerate(predictions):\n",
        "    # print char using argmax, dict\n",
        "    result_str = [idx2char[c] for c in np.argmax(prediction, axis=1)]\n",
        "    print(\"\\tPrediction str: \", ''.join(result_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L2xclvsxJyf",
        "outputId": "de61ad67-71b1-44ac-9ca1-6c4a87f267aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c5cedbdcca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 331ms/step\n",
            "\tPrediction str:  u  uuuou     uu\n"
          ]
        }
      ]
    }
  ]
}