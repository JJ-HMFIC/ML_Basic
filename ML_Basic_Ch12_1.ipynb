{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGFUTikRrJQcc8lh9lQ7qO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJ-HMFIC/ML_Basic/blob/main/ML_Basic_Ch12_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ch 12"
      ],
      "metadata": {
        "id": "JCb40MgBwlsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "B6i21TKawI0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
        "# Teach hello: hihell -> ihello\n",
        "# x_data = [[0, 1, 0, 2, 3, 3]]  # hihell\n",
        "y_data = [[1, 0, 2, 3, 3, 4]]  # ihello"
      ],
      "metadata": {
        "id": "BSv9VN8Mrbgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5\n",
        "input_dim = 5  # one-hot size, same as hidden_size to directly predict one-hot\n",
        "sequence_length = 6  # |ihello| == 6\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "ZHiIX6p6rnG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_one_hot = np.array([[[1, 0, 0, 0, 0],    # h 0\n",
        "                       [0, 1, 0, 0, 0],    # i 1\n",
        "                       [1, 0, 0, 0, 0],    # h 0\n",
        "                       [0, 0, 1, 0, 0],    # e 2\n",
        "                       [0, 0, 0, 1, 0],    # l 3\n",
        "                       [0, 0, 0, 1, 0]]],  # l 3\n",
        "                     dtype=np.float32)"
      ],
      "metadata": {
        "id": "cMhO2FGqrsr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot = tf.keras.utils.to_categorical(y_data, num_classes=num_classes)\n",
        "print(x_one_hot.shape)\n",
        "print(y_one_hot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6NDjLe9rveA",
        "outputId": "53362155-f121-4330-fe30-7181752518ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 6, 5)\n",
            "(1, 6, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "upDILfnyrwti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make cell and add it to RNN layer\n",
        "# input_shape = (1,6,5) => number of sequence (batch), length of sequence, size of input dim\n",
        "\n",
        "cell = tf.keras.layers.LSTMCell(units=num_classes, input_shape=(sequence_length, input_dim))\n",
        "# LSTMCell은 LSTM(Long Short-Term Memory) 네트워크의 하나의 셀을 정의\n",
        "# units 매개변수는 LSTM 셀의 출력 크기\n",
        "# input_shape는 입력 데이터의 형태를 정의\n",
        "# sequence_length는 시퀀스의 길이, input_dim은 입력 벡터의 차원\n",
        "\n",
        "model.add(tf.keras.layers.RNN(cell=cell, return_sequences=True))\n",
        "# RNN 레이어는 주어진 셀(cell)을 사용하여 RNN을 구성\n",
        "# return_sequences=True로 설정되어 있으므로, 이 RNN 레이어는 출력 시퀀스를 반환\n",
        "# 만약 return_sequences를 False로 설정하면, 마지막 시간 단계의 출력만 반환"
      ],
      "metadata": {
        "id": "t2YTxml5rzGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# single LSTM layer can be used as well instead of creating LSTMCell\n",
        "# tf.model.add(tf.keras.layers.LSTM(units=num_classes, input_shape=(sequence_length, input_dim), return_sequences=True))\n",
        "\n",
        "# fully connected layer\n",
        "model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))\n",
        "# TimeDistributed 레이어는 내부에 있는 레이어를 시간 분배(distribute)하여 각 시간 단계에서 같은 가중치를 사용하는 레이어\n",
        "# Dense 레이어는 완전 연결 층을 의미\n",
        "# num_classes는 출력의 개수\n",
        "# 출력을 확률 분포로 변환하기 위해 소프트맥스 활성화 함수를 사용\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                 metrics=['accuracy'])\n",
        "# metrics는 모델의 성능을 측정할 지표로, 여기서는 정확도('accuracy')를 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d190lm28r26c",
        "outputId": "883e6056-36ec-4ccc-c7ef-0e1a120104cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "model.fit(x_one_hot, y_one_hot, epochs=50)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPjiZ4bpsYvO",
        "outputId": "b04b43f6-7cb6-4db9-de87-ebf66b0b7968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4647 - accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4634 - accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4622 - accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4609 - accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4597 - accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4584 - accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4571 - accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4559 - accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4546 - accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4533 - accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4520 - accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4508 - accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4495 - accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4482 - accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4469 - accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4456 - accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4443 - accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4430 - accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4417 - accuracy: 0.3333\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4404 - accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4391 - accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4378 - accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4365 - accuracy: 0.5000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.4352 - accuracy: 0.5000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4339 - accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4326 - accuracy: 0.5000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.4313 - accuracy: 0.5000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4300 - accuracy: 0.5000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4287 - accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4273 - accuracy: 0.5000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4260 - accuracy: 0.5000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4247 - accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4234 - accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4221 - accuracy: 0.5000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.4207 - accuracy: 0.5000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4194 - accuracy: 0.5000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4181 - accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4168 - accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4154 - accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4141 - accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4128 - accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4114 - accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.4101 - accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.4088 - accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4074 - accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4061 - accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.4047 - accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.4034 - accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4020 - accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.4007 - accuracy: 0.5000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rnn (RNN)                   (None, 6, 5)              220       \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 6, 5)              30        \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDi  (None, 6, 5)              30        \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 280 (1.09 KB)\n",
            "Trainable params: 280 (1.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_one_hot)\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(prediction)\n",
        "    # print char using argmax, dict\n",
        "    result_str = [idx2char[c] for c in np.argmax(prediction, axis=1)]\n",
        "    print(\"\\tPrediction str: \", ''.join(result_str))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us16ATVxttwn",
        "outputId": "28917351-311e-48a5-ac87-ecd33f5e0a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "[[0.20831332 0.20931685 0.18990122 0.27444676 0.11802179]\n",
            " [0.20996173 0.21346848 0.19188713 0.27454385 0.11013877]\n",
            " [0.21071006 0.21762232 0.19450228 0.27486882 0.10229656]\n",
            " [0.18909988 0.19129631 0.16272466 0.30719653 0.14968257]\n",
            " [0.18087387 0.15218899 0.13989438 0.29181442 0.23522836]\n",
            " [0.1781055  0.13063982 0.12936418 0.2673108  0.29457968]]\n",
            "\tPrediction str:  lllllo\n"
          ]
        }
      ]
    }
  ]
}